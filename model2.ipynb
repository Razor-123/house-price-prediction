{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "from json import JSONEncoder\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df0 = pd.read_csv('train.csv')\n",
    "test_df0 = pd.read_csv('test.csv')\n",
    "train_df1 = train_df0.append(test_df0,ignore_index=True)\n",
    "train_df1['rent'] = train_df1['rent'].fillna(0)\n",
    "train_df2 = train_df1.drop(['id'],axis=1)\n",
    "train_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df2 = train_df2[[c for c in train_df2 if c not in ['rent']] + ['rent']]\n",
    "# train_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dummies = pd.get_dummies(train_df2['type'])\n",
    "locality_dummies = pd.get_dummies(train_df2['locality'])\n",
    "lease_dummies = pd.get_dummies(train_df2['lease_type'])\n",
    "furnishing_dummies = pd.get_dummies(train_df2['furnishing'])\n",
    "parking_dummies = pd.get_dummies(train_df2['parking'])\n",
    "water_dummies = pd.get_dummies(train_df2['water_supply'])\n",
    "building_dummies = pd.get_dummies(train_df2['building_type'])\n",
    "facing_dummies = pd.get_dummies(train_df2['facing'])\n",
    "train_df3 = train_df2.drop(['type','locality','lease_type','furnishing','parking','water_supply','building_type','facing','activation_date','amenities'],axis=1)\n",
    "train_df4 = pd.concat([type_dummies,locality_dummies,lease_dummies,furnishing_dummies,parking_dummies,water_dummies,building_dummies,facing_dummies,train_df3],axis=1)\n",
    "train_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_train = scaler.fit_transform(train_df4)\n",
    "scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplied_by = scaler.scale_[scaled_train.shape[1]-1]\n",
    "added = scaler.min_[scaled_train.shape[1]-1]\n",
    "multiplied_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_df = pd.DataFrame(scaled_train, columns=train_df4.columns.values)\n",
    "scaled_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'rent'\n",
    "X = scaled_train_df.drop(target, axis=1).values\n",
    "Y = scaled_train_df[[target]].values\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X[10:20499],\n",
    "    Y[10:20499],\n",
    "    epochs=20,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X[0:1])\n",
    "y_0 = prediction[0][0]\n",
    "print('Prediction with scaling - {}',format(y_0))\n",
    "y_0 -= added\n",
    "y_0 /= multiplied_by\n",
    "print(\"Housing Price Prediction  - ${}\".format(y_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_list = []\n",
    "for i in range(20500,25000):\n",
    "    prediction = model.predict(X[i:i+1])\n",
    "    ans = prediction[0][0]\n",
    "    ans -= added\n",
    "    ans /= multiplied_by\n",
    "    ans_list.append(ans)\n",
    "ans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [int(item) for item in ans_list]\n",
    "df = pd.DataFrame(result,columns=['rent'])\n",
    "df\n",
    "df.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model('my_model.h5')\n",
    "multiplied_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model2.predict(X[:1])\n",
    "print(X[:1].shape)\n",
    "y_0 = prediction[0][0]\n",
    "print('Prediction with scaling - {}',format(y_0))\n",
    "y_0 -= added\n",
    "y_0 /= multiplied_by\n",
    "print(\"Housing Price Prediction  - ${}\".format(y_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locality_data = locality_dummies.columns.to_numpy()\n",
    "\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "        \n",
    "json_data = {\"array\":locality_data}\n",
    "with open(\"locality_array.json\", \"w\") as write_file:\n",
    "    json.dump(json_data, write_file, cls=NumpyArrayEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_df['longitude'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = json.loads(train_df2['amenities'][0])\n",
    "dict\n",
    "for ele in dict:\n",
    "    if dict[ele]==False:\n",
    "        print(ele)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a12d694c3ccac42055183a0ad11e659c6a2db5c6555ad2c8919d5814fd4e404f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
